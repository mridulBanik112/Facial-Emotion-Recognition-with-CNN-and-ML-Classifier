{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DIR = 'J:/SONGS/LAP DOWNLOAD/GEETA/Compressed/Data of saudia/Data of saudia'\n",
    "# TRAIN_DIR = 'C:/Users/DELL/SkyDrive/Documents/data2/train_data'\n",
    "TRAIN_DIR = 'E:/full stack python/Traine_DATA/Traine_DATA'\n",
    "# TEST_DIR = 'J:/SONGS/LAP DOWNLOAD/GEETA/Compressed/Data of saudia/tes'\n",
    "# TEST_DIR = 'C:/Users/DELL/SkyDrive/Documents/data2/test_data'\n",
    "TEST_DIR = 'E:/full stack python/Test_DATA/Test_DATA'\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    " \n",
    " \n",
    "'''Setting up the model which will help with tensorflow models'''\n",
    "MODEL_NAME = 'Autistic-{}-{}.model'.format(LR, '6conv-basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')#[-3]\n",
    "    s=word_label[0]\n",
    " # DIY One hot encoder\n",
    "#     if 'happy' in s : \n",
    "#         return [1, 0, 0, 0]\n",
    "#     elif 'sad' in  s: \n",
    "#         return [0, 1, 0, 0]\n",
    "#     elif 'angry' in  s: \n",
    "#         return [0, 0, 1, 0] \n",
    "#     elif 'normal' in  s: \n",
    "#         return [0, 0, 0, 1] \n",
    "    if 'appy' in s : \n",
    "        return [1, 0, 0, 0]\n",
    "    elif 'sad' in  s: \n",
    "        return [0, 1, 0, 0]\n",
    "    elif 'ngry' in  s: \n",
    "        return [0, 0, 1, 0] \n",
    "    elif (('ormal' in  s ) or ('eutral' in  s)): \n",
    "        return [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    # Creating an empty list where we should the store the training data\n",
    "    # after a little preprocessing of the data\n",
    "    training_data = []\n",
    " \n",
    "    # tqdm is only used for interactive loading\n",
    "    # loading the training data\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    " \n",
    "        # labeling the images\n",
    "        label = label_img(img)\n",
    " \n",
    "        path = os.path.join(TRAIN_DIR, img)\n",
    " \n",
    "        # loading the image from the path and then converting them into\n",
    "        # greyscale for easier covnet prob\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    " \n",
    "        # resizing the image for processing them in the covnet\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    " \n",
    "        # final step-forming the training data list with numpy array of the images\n",
    "        training_data.append([np.array(img), np.array(label)])\n",
    " \n",
    "    # shuffling of the training data to preserve the random state of our data\n",
    "    shuffle(training_data)\n",
    " \n",
    "    # saving our trained data for further uses if required\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "         \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1228/1228 [01:06<00:00, 18.56it/s]\n",
      "100%|████████████████████████████████████████| 299/299 [00:28<00:00, 10.44it/s]\n"
     ]
    }
   ],
   "source": [
    "'''Running the training and the testing in the dataset for our model'''\n",
    "train_data = create_train_data()\n",
    "test_data = process_test_data()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1228"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0]\n",
    "type(train_data)\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    " \n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "convnet = input_data(shape =[None, IMG_SIZE, IMG_SIZE, 1], name ='input')\n",
    " \n",
    "convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    " \n",
    "convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    " \n",
    "convnet = conv_2d(convnet, 128, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    " \n",
    "convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    " \n",
    "convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    " \n",
    "convnet = fully_connected(convnet, 1024, activation ='relu')\n",
    "convnet = dropout(convnet, 0.3)\n",
    " \n",
    "convnet = fully_connected(convnet, 4, activation ='softmax')\n",
    "convnet = regression(convnet, optimizer ='adam', learning_rate = LR,\n",
    "      loss ='categorical_crossentropy', name ='targets')\n",
    " \n",
    "model = tflearn.DNN(convnet, tensorboard_dir ='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomX shape (1228, 2500)\n",
      "(1228, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random classifier model implementation\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "# clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "RandomX = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "RandomY = [i[1] for i in train_data]\n",
    "# RandomX=RandomX.reshape(27,2500)\n",
    "RandomX=RandomX.reshape(len(train_data),IMG_SIZE*IMG_SIZE)\n",
    "print(\"RandomX shape\",RandomX.shape)\n",
    "\n",
    "#  svm y editing\n",
    "svm_y = []\n",
    "for val in RandomY:\n",
    "    if np.argmax(val) == 0:\n",
    "#         str_label ='Happy'\n",
    "        svm_y.append(0)\n",
    "    elif np.argmax(val) == 1:\n",
    "#         str_label ='sad'\n",
    "        svm_y.append(1)\n",
    "    elif np.argmax(val) == 2:\n",
    "#         str_label ='Angry'\n",
    "        svm_y.append(2)\n",
    "    elif np.argmax(val) == 3:\n",
    "#         str_label ='normal'\n",
    "        svm_y.append(3)\n",
    "\n",
    "\n",
    "RandomY_numpy_array = np.array(RandomY)\n",
    "# type(RandomX)\n",
    "# print((RandomY))\n",
    "# print((RandomY.shape))\n",
    "print((RandomY_numpy_array.shape))\n",
    "# print((RandomY.ndim))\n",
    "clf.fit(RandomX,RandomY)\n",
    "s_v_m = svm.SVC(gamma=0.001,C=100)\n",
    "s_v_m.fit(RandomX,svm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n",
    "int(len(train_data) * .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the testing data and training data\n",
    "split_value=int(len(train_data) * .3) # 30 /70 split \n",
    "train = train_data[:-split_value]\n",
    "test = train_data[-split_value:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-Features & Y-Labels\n",
    " \n",
    "X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Y = [i[1] for i in train]\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "test_y = [i[1] for i in test]\n",
    "# print(\"test_y\",len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 139  | total loss: 0.95516 | time: 3.267s\n",
      "| Adam | epoch: 010 | loss: 0.95516 - acc: 0.5590 -- iter: 832/860\n",
      "Training Step: 140  | total loss: 0.98774 | time: 4.543s\n",
      "| Adam | epoch: 010 | loss: 0.98774 - acc: 0.5469 | val_loss: 1.10116 - val_acc: 0.5190 -- iter: 860/860\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\DELL\\Autistic-0.001-6conv-basic.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model_details = model.fit({'input': X}, {'targets': Y}, n_epoch = 10, \n",
    "    validation_set =({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step = 2000, show_metric = True, run_id = MODEL_NAME)\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[0, 2, 1, 3, 2, 3, 1, 2, 0, 2, 0, 0, 0, 0, 2, 3, 1, 1, 1, 3, 0, 1, 1, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 3, 2, 2, 2, 2, 1, 1, 3, 2, 0, 2, 2, 0, 3, 1, 0, 2, 2, 2, 0, 1, 0, 1, 2, 2, 2, 0, 0, 2, 1, 1, 1, 2, 1, 3, 0, 0, 2, 2, 2, 0, 1, 2, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 1, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 1, 1, 0, 2, 2, 3, 1, 0, 1, 1, 0, 3, 0, 1, 0, 0, 2, 3, 0, 0, 2, 2, 2, 2, 3, 2, 2, 1, 2, 0, 0, 3, 0, 3, 2, 1, 1, 0, 3, 1, 2, 0, 0, 0, 2, 1, 2, 2, 0, 2, 0, 3, 2, 1, 3, 2, 2, 1, 2, 0, 0, 1, 2, 2, 2, 0, 3, 0, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 3, 2, 3, 2, 1, 1, 2, 3, 0, 0, 1, 2, 2, 1, 0, 0, 2, 0, 0, 1, 2, 0, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 0, 2, 1, 3, 1, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 1, 0, 2, 0, 0, 2, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 3, 0, 0, 0, 1, 2, 0, 3, 3, 2, 0, 2, 1]\n",
      "Accuracy cnn : 0.5585284280936454\n"
     ]
    }
   ],
   "source": [
    "'''Testing the data'''\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "# if you need to create the data:\n",
    "# test_data = process_test_data()\n",
    "# if you already have some saved:\n",
    "test_data = np.load('test_data.npy')\n",
    " \n",
    "# fig = plt.figure()\n",
    "Label_OF_test_data = [] \n",
    "Predicted_label = []\n",
    "Predicted_label_RandomForest = []\n",
    "b = True\n",
    "\n",
    "\n",
    "for num, data in enumerate(test_data):\n",
    "    # cat: [1, 0]\n",
    "    # dog: [0, 1]\n",
    "     \n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "#     print(img_num)\n",
    "#     if 'happy' in img_num : \n",
    "#         Label_OF_test_data.append(0)\n",
    "#     elif 'sad' in  img_num: \n",
    "#         Label_OF_test_data.append(1)\n",
    "#     elif 'angry' in  img_num: \n",
    "#         Label_OF_test_data.append(2)\n",
    "#     elif 'normal' in  img_num: \n",
    "#         Label_OF_test_data.append(3)\n",
    "#             return [1, 0, 0, 0]\n",
    "    if 'appy' in img_num : \n",
    "        Label_OF_test_data.append(0)\n",
    "    elif 'sad' in  img_num: \n",
    "        Label_OF_test_data.append(1)\n",
    "    elif 'ngry' in  img_num: \n",
    "        Label_OF_test_data.append(2) \n",
    "    elif (('ormal' in  img_num ) or ('eutral' in  img_num)): \n",
    "        Label_OF_test_data.append(3)\n",
    "        \n",
    "    \n",
    "#     y = fig.add_subplot(4, 5, num + 1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    " \n",
    "    # model_out = model.predict([data])[0]\n",
    "#     print(data.shape)\n",
    "#     print(data.ndim)\n",
    "    \n",
    "    dataRC=data.reshape(1,IMG_SIZE*IMG_SIZE)\n",
    "#     print(dataRC.shape)\n",
    "#     print(dataRC.ndim)\n",
    "#     if b:\n",
    "#         break\n",
    "    model_out = model.predict([data])[0]\n",
    "#     print(np.argmax(model_out))\n",
    "    if np.argmax(model_out) == 0:\n",
    "#         str_label ='Happy'\n",
    "        Predicted_label.append(0)\n",
    "    elif np.argmax(model_out) == 1:\n",
    "#         str_label ='sad'\n",
    "        Predicted_label.append(1)\n",
    "    elif np.argmax(model_out) == 2:\n",
    "#         str_label ='Angry'\n",
    "        Predicted_label.append(2)\n",
    "    elif np.argmax(model_out) == 3:\n",
    "#         str_label ='normal'\n",
    "        Predicted_label.append(3)\n",
    "    \n",
    "        \n",
    "\n",
    "score=metrics.accuracy_score(Label_OF_test_data, Predicted_label)\n",
    "print(Label_OF_test_data)\n",
    "print(Predicted_label)\n",
    "print('Accuracy cnn : {}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(299, 50, 50, 1)\n",
      "2\n",
      "(299, 2500)\n",
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[0, 0, 1, 0, 2, 3, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 3, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 1, 1, 0, 0, 0, 2, 0, 0, 3, 1, 0, 2, 0, 0, 2, 1, 0, 1, 0, 2, 0, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 0, 0, 1, 3, 2, 0, 0, 2, 2, 2, 0, 3, 0, 0, 2, 2, 1, 2, 0, 0, 0, 0, 2, 0, 1, 1, 0, 3, 1, 0, 0, 0, 0, 2, 1, 2, 0, 2, 3, 0, 0, 0, 1, 3, 0, 2, 1, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 3, 2, 2, 0, 1, 0, 0, 3, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 3, 1, 2, 1, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 3, 3, 2, 3, 0, 0, 0, 1, 2, 0, 3, 0, 3, 0, 2, 1]\n",
      "Accuracy RANDOM CLASSIFIER: 0.5886287625418061\n"
     ]
    }
   ],
   "source": [
    "# RANDOM CLASSIFIER PREDICTION\n",
    "\n",
    "test_Xrc = np.array([i[0] for i in test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "print(test_Xrc.ndim)\n",
    "print(test_Xrc.shape)\n",
    "test_Xrc=test_Xrc.reshape(len(test_Xrc),IMG_SIZE*IMG_SIZE)\n",
    "print(test_Xrc.ndim)\n",
    "print(test_Xrc.shape)\n",
    "# *************************IMPLEMENTING rANDOM fOREST MODEL ******************************************\n",
    "pred_rc=clf.predict(test_Xrc)\n",
    "# print(pred_rc)\n",
    "final_pred_rc=[]\n",
    "for val in pred_rc:\n",
    "    if np.argmax(val) == 0:\n",
    "#         str_label ='Happy'\n",
    "        final_pred_rc.append(0)\n",
    "    elif np.argmax(val) == 1:\n",
    "#         str_label ='sad'\n",
    "        final_pred_rc.append(1)\n",
    "    elif np.argmax(val) == 2:\n",
    "#         str_label ='Angry'\n",
    "        final_pred_rc.append(2)\n",
    "    elif np.argmax(val) == 3:\n",
    "#         str_label ='normal'\n",
    "        final_pred_rc.append(3)\n",
    "# RC ACCURACY CHECK\n",
    "\n",
    "score=metrics.accuracy_score(Label_OF_test_data, final_pred_rc)\n",
    "print(Label_OF_test_data)\n",
    "print(final_pred_rc)\n",
    "print('Accuracy RANDOM CLASSIFIER: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2]\n",
      "Accuracy SVM: 0.25418060200668896\n"
     ]
    }
   ],
   "source": [
    "#  implemrnting SVM \n",
    "pred_svm=[]\n",
    "pred_svm=s_v_m.predict(test_Xrc)\n",
    "# print(pred_rc)\n",
    "#  accuracy scheck svm\n",
    "\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_svm)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_svm)\n",
    "print('Accuracy SVM: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[1 0 1 2 3 3 1 0 0 3 2 2 0 3 0 2 1 1 1 0 1 1 1 3 2 2 2 2 2 0 3 2 2 2 2 3 1\n",
      " 0 1 1 3 3 0 2 2 0 3 1 3 2 3 2 2 1 2 1 0 3 3 3 3 0 1 1 1 0 0 0 3 2 2 0 3 2\n",
      " 1 2 3 3 3 1 3 2 2 0 0 3 0 1 1 1 2 3 0 0 2 3 2 0 2 0 3 3 3 1 2 1 3 2 2 1 1\n",
      " 0 1 1 0 3 0 1 0 0 0 3 2 0 3 2 3 0 3 3 1 1 2 2 2 0 3 2 2 1 0 0 3 1 1 2 0 2\n",
      " 2 2 2 1 2 3 2 2 1 1 3 2 2 1 3 0 3 2 3 2 0 3 3 0 0 1 3 2 3 2 1 2 0 1 0 1 2\n",
      " 2 2 3 1 0 0 2 2 2 1 0 0 1 1 2 3 3 0 1 3 0 1 3 2 1 3 1 2 0 1 2 1 2 2 2 1 2\n",
      " 0 1 3 3 2 2 2 3 0 2 2 1 1 1 1 3 3 3 3 3 1 2 3 3 1 1 1 1 1 1 1 0 1 0 3 0 3\n",
      " 2 2 2 0 2 2 3 2 2 3 0 0 1 3 3 0 2 0 2 2 2 3 0 3 3 3 2 3 1 3 3 1 2 0 3 3 3\n",
      " 3 2 1]\n",
      "Accuracy LogisticRegression : 0.5050167224080268\n"
     ]
    }
   ],
   "source": [
    "# implementing Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all parameters not specified are set to their defaults# all pa \n",
    "# default solver is incredibly slow thats why we change it\n",
    "# solver = 'lbfgs'\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "logisticRegr.fit(RandomX, svm_y)\n",
    "pred_logReg=logisticRegr.predict(test_Xrc)\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_logReg)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_logReg)\n",
    "print('Accuracy LogisticRegression : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[1 2 1 2 2 3 1 0 3 3 3 2 0 2 2 3 1 1 1 2 2 1 1 0 2 2 2 0 2 1 2 2 2 2 2 3 2\n",
      " 0 1 1 2 1 1 0 2 0 3 1 0 2 1 3 0 1 2 1 3 2 3 2 1 2 1 1 1 2 1 0 2 2 2 0 3 2\n",
      " 1 2 1 2 1 1 0 2 0 0 0 2 0 1 1 1 2 2 2 0 0 2 2 0 2 0 2 3 3 1 1 1 0 0 2 3 1\n",
      " 1 1 1 1 3 3 1 3 2 2 3 2 0 2 0 3 0 0 2 2 1 2 3 0 1 3 2 3 1 1 0 3 1 2 2 3 0\n",
      " 0 1 2 1 2 0 3 3 0 1 3 0 2 1 0 3 0 1 2 2 2 0 2 0 3 1 1 1 2 1 3 2 2 1 0 1 3\n",
      " 2 2 3 1 0 3 3 2 2 1 2 3 1 0 2 0 3 0 1 0 3 1 3 2 1 1 2 1 2 3 2 1 2 2 2 1 3\n",
      " 0 1 2 3 3 3 0 3 3 3 0 3 1 1 1 2 1 3 1 2 1 3 1 3 1 0 1 1 3 0 3 3 1 3 3 0 2\n",
      " 2 2 0 1 2 2 0 0 1 3 0 0 0 0 0 1 3 2 0 0 2 1 3 1 3 3 2 3 0 2 2 1 2 0 3 3 3\n",
      " 0 2 1]\n",
      "Accuracy KNN : 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "# KNN IMPLEMENTATION\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(RandomX, svm_y)\n",
    "pred_knn=neigh.predict(test_Xrc)\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_knn)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_knn)\n",
    "print('Accuracy KNN : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[2 2 1 3 2 3 3 3 0 2 0 2 3 0 2 2 1 0 1 2 2 0 1 3 3 2 3 2 2 1 3 2 1 3 3 3 0\n",
      " 0 1 1 3 2 0 0 0 0 2 2 3 2 2 1 2 3 2 3 2 0 2 3 3 2 3 3 3 0 1 0 2 1 3 3 2 0\n",
      " 0 2 2 3 2 1 3 2 3 0 0 2 0 1 1 1 2 3 0 0 2 3 0 3 2 0 2 3 3 3 1 1 2 0 3 0 3\n",
      " 1 0 0 0 3 0 1 2 0 3 3 2 2 3 3 3 2 0 2 0 3 0 2 3 2 1 2 2 1 0 3 2 1 0 0 0 0\n",
      " 3 1 2 1 3 2 2 2 0 1 3 2 2 1 2 0 2 1 3 0 2 3 3 2 2 1 0 2 3 0 0 0 2 1 0 1 3\n",
      " 3 2 2 1 2 2 2 1 2 1 2 2 1 0 3 3 3 2 1 2 0 1 0 2 1 2 0 0 0 0 2 3 2 3 2 1 2\n",
      " 3 1 3 3 0 2 2 2 2 0 0 3 1 1 0 3 3 3 3 3 1 0 3 3 1 1 1 0 3 1 0 2 1 2 3 3 3\n",
      " 0 3 3 1 2 0 3 3 3 0 1 2 3 3 3 2 3 0 0 2 2 3 0 3 3 3 3 3 3 1 2 0 0 0 3 3 3\n",
      " 2 0 0]\n",
      "Accuracy LinearDiscriminantAnalysis : 0.3979933110367893\n"
     ]
    }
   ],
   "source": [
    "# LinearDiscriminantAnalysis IMPLEMENTATION\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(RandomX, svm_y)\n",
    "pred_LinearDiscriminantAnalysis=clf.predict(test_Xrc)\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_LinearDiscriminantAnalysis)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_LinearDiscriminantAnalysis)\n",
    "print('Accuracy LinearDiscriminantAnalysis : {}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[1 1 1 3 2 3 1 0 1 1 2 0 0 2 0 3 1 0 1 2 2 1 1 2 2 2 2 0 2 0 2 1 0 0 2 2 2\n",
      " 1 1 1 3 0 1 2 0 0 2 1 1 2 3 0 2 1 2 1 2 2 1 0 0 2 1 1 1 2 1 3 0 2 1 1 2 0\n",
      " 1 2 0 0 1 3 3 2 3 1 1 0 3 1 1 1 0 0 2 1 1 3 2 2 2 2 0 0 3 0 1 1 3 2 2 0 1\n",
      " 0 1 1 1 2 0 1 1 2 0 3 0 2 1 2 2 2 0 2 2 1 2 2 3 2 0 0 2 1 1 0 0 1 0 2 1 1\n",
      " 2 1 2 0 0 2 2 2 2 1 0 2 1 1 0 2 1 1 2 2 0 1 3 1 2 1 1 1 2 1 0 1 0 1 0 1 3\n",
      " 2 2 1 1 0 0 2 0 2 1 0 2 1 0 0 0 1 0 1 2 0 1 0 1 1 2 0 1 3 0 2 1 0 1 1 1 2\n",
      " 0 1 2 3 0 2 2 0 2 2 2 2 1 1 1 2 2 2 1 3 1 0 0 3 1 2 1 1 1 1 1 1 1 0 2 1 2\n",
      " 1 2 2 1 2 2 3 2 1 2 2 1 1 2 0 0 0 2 2 2 2 1 0 3 3 3 0 2 0 2 0 1 2 1 3 2 2\n",
      " 1 2 1]\n",
      "Accuracy GaussianNB : 0.47157190635451507\n"
     ]
    }
   ],
   "source": [
    "# GaussianNB IMPLEMENTATION\n",
    "clf = GaussianNB()\n",
    "clf.fit(RandomX, svm_y)\n",
    "pred_GaussianNB=clf.predict(test_Xrc)\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_GaussianNB)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_GaussianNB)\n",
    "print('Accuracy GaussianNB : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[1 3 1 3 2 2 1 0 0 0 0 0 0 2 0 2 1 1 1 3 0 1 1 2 2 2 2 0 2 0 3 3 3 3 2 3 2\n",
      " 0 1 0 2 0 1 2 3 0 3 1 1 2 1 0 2 2 2 1 2 2 1 2 1 2 1 1 3 2 0 2 2 2 3 0 0 2\n",
      " 1 2 2 3 3 1 1 2 0 0 0 1 0 1 1 0 2 1 3 0 0 2 2 0 0 2 0 1 3 1 1 1 0 3 3 2 1\n",
      " 3 1 0 0 0 2 0 3 2 2 0 0 2 2 3 0 2 3 2 2 1 0 0 3 3 0 3 0 1 0 0 0 1 0 2 1 2\n",
      " 3 1 3 3 2 3 2 0 2 1 3 3 2 1 3 3 0 1 2 2 0 1 2 2 3 1 0 2 0 3 0 2 0 1 0 1 3\n",
      " 3 2 2 1 0 0 2 1 2 1 2 2 1 2 3 2 2 0 1 2 1 1 0 2 1 0 3 1 3 3 2 1 2 3 2 2 3\n",
      " 0 1 2 3 2 3 0 1 3 3 3 0 1 1 1 3 3 3 0 2 1 0 0 3 0 2 1 1 3 3 3 3 1 2 3 2 1\n",
      " 2 0 3 1 2 2 3 0 1 3 3 0 0 3 0 3 3 3 3 2 2 1 2 2 3 3 2 2 2 3 0 1 0 0 3 2 3\n",
      " 3 3 1]\n",
      "Accuracy DecisionTreeClassifier : 0.45484949832775917\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier \n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(RandomX, svm_y)\n",
    "pred_DecisionTreeClassifier=clf.predict(test_Xrc)\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_DecisionTreeClassifier)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_DecisionTreeClassifier)\n",
    "print('Accuracy DecisionTreeClassifier : {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This part of code is implementing PCA and ml algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************** PCA + lOGISTIC REGRESSION *****************\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228, 2500)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1228, 2500)\n",
      "1228\n",
      "(299, 2500)\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "# Pca_X = []\n",
    "# Pca_Y = []\n",
    "Pca_train_X = []\n",
    "Pca_test__X=[]\n",
    "Pca_train_X=RandomX\n",
    "Pca_test_X=test_Xrc\n",
    "print(Pca_train_X.shape)\n",
    "print(len(Pca_train_X))\n",
    "print(Pca_test_X.shape)\n",
    "print(len(Pca_test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(Pca_train_X)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "Pca_train_X = scaler.transform(Pca_train_X)\n",
    "Pca_test_X = scaler.transform(Pca_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.95)\n",
    "pca.fit(Pca_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pca_train_X = pca.transform(Pca_train_X)\n",
    "Pca_test_X = pca.transform(Pca_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all parameters not specified are set to their defaults# all pa \n",
    "# default solver is incredibly slow thats why we change it\n",
    "# solver = 'lbfgs'\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "logisticRegr.fit(Pca_train_X, svm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logReg=logisticRegr.predict(Pca_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[1 0 1 3 2 2 1 0 2 3 0 2 0 3 0 3 1 1 1 3 1 1 1 3 2 2 1 3 2 0 3 2 2 2 2 2 2\n",
      " 0 1 1 3 3 0 2 2 0 3 1 3 2 3 2 2 1 0 1 2 2 3 3 3 0 1 1 1 2 1 2 3 2 2 0 3 0\n",
      " 1 2 0 3 3 1 3 2 0 0 0 0 0 1 1 1 2 3 0 0 2 3 2 0 2 0 2 2 3 1 1 1 2 2 2 1 1\n",
      " 0 1 1 1 3 0 1 0 2 2 3 2 0 3 2 3 3 2 3 2 1 2 2 3 0 0 3 0 1 0 0 0 1 1 2 0 0\n",
      " 2 1 2 1 2 3 2 2 1 1 0 0 2 1 3 0 0 1 2 2 0 0 3 0 3 1 3 2 2 2 0 2 0 1 0 1 3\n",
      " 2 2 3 1 0 0 2 2 2 1 1 2 1 1 3 3 3 0 1 3 0 1 0 2 1 3 0 2 0 1 2 1 2 2 2 1 2\n",
      " 0 1 1 3 2 3 2 3 0 0 2 3 1 1 1 3 1 0 3 0 1 2 3 3 1 1 1 1 0 1 1 0 1 3 3 0 3\n",
      " 2 2 2 0 2 0 0 2 2 3 0 0 1 2 1 3 2 2 0 0 2 1 0 0 3 0 2 0 1 2 3 1 2 0 3 3 3\n",
      " 3 2 1]\n",
      "Accuracy PCA + LogisticRegression : 0.5785953177257525\n"
     ]
    }
   ],
   "source": [
    "score=metrics.accuracy_score(Label_OF_test_data, pred_logReg)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_logReg)\n",
    "print('Accuracy PCA + LogisticRegression : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[0 2 1 3 2 3 1 0 3 3 2 2 0 3 2 3 1 2 1 3 0 1 1 3 2 2 2 2 2 0 3 2 2 2 2 3 2\n",
      " 3 1 1 2 3 3 2 2 0 3 1 0 2 3 3 3 1 2 1 3 2 0 2 3 2 1 1 1 2 1 0 2 0 2 0 0 2\n",
      " 1 0 0 3 1 2 0 2 0 0 0 3 0 1 1 1 2 2 3 0 0 2 2 0 2 0 2 3 3 1 1 1 2 0 2 3 1\n",
      " 3 1 1 3 0 0 1 3 2 0 3 2 2 0 3 3 0 2 2 2 1 2 3 0 3 0 2 3 1 1 0 3 1 0 0 3 0\n",
      " 3 1 2 0 2 3 2 3 2 1 0 0 2 1 0 0 0 1 2 2 2 0 3 3 2 1 0 1 2 1 0 2 0 1 0 1 3\n",
      " 2 2 3 1 0 0 3 2 2 1 2 3 1 0 0 0 3 0 1 3 0 1 0 2 1 3 0 1 2 1 0 1 2 2 2 1 3\n",
      " 0 2 2 3 3 3 0 3 3 3 0 3 1 1 1 3 1 2 0 2 1 3 2 3 1 2 1 1 3 3 3 3 1 3 3 0 2\n",
      " 2 3 0 1 2 0 3 0 1 3 0 0 0 3 0 1 1 2 0 0 2 0 0 0 3 3 2 3 0 2 2 1 2 0 3 3 3\n",
      " 3 2 1]\n",
      "Accuracy PCA + SVM: 0.6822742474916388\n"
     ]
    }
   ],
   "source": [
    "# **************************** PCA + SVM *****************\n",
    "s_v_m.fit(Pca_train_X,svm_y)\n",
    "pred_svm_pca=s_v_m.predict(Pca_test_X)\n",
    "# print(pred_rc)\n",
    "#  accuracy scheck svm\n",
    "\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_svm_pca)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_svm_pca)\n",
    "print('Accuracy PCA + SVM: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[2 0 1 0 2 2 1 0 2 2 0 2 0 2 2 2 1 0 1 0 2 1 1 3 2 2 0 2 2 3 2 2 2 2 2 3 2\n",
      " 2 1 1 0 3 2 2 2 2 3 2 0 2 3 2 2 3 2 1 0 2 3 2 0 2 1 1 1 3 3 0 2 2 2 0 2 0\n",
      " 1 2 2 0 2 2 2 2 0 0 0 2 0 1 1 2 2 0 2 0 3 2 2 0 2 0 2 0 3 0 2 2 2 2 2 0 1\n",
      " 3 1 1 0 0 0 1 2 2 0 2 2 2 2 2 3 2 0 2 2 1 2 0 3 0 0 2 0 1 0 2 3 2 0 2 0 0\n",
      " 2 2 2 2 2 2 2 2 0 1 0 0 2 1 2 0 0 1 2 2 0 0 3 2 2 1 0 0 2 0 0 2 0 1 0 1 2\n",
      " 2 2 3 1 0 0 0 0 2 1 2 2 1 0 0 0 2 0 1 2 0 1 0 2 2 0 0 2 3 0 2 1 2 2 2 1 2\n",
      " 0 1 2 3 0 2 2 2 0 3 0 3 1 1 1 3 0 0 2 2 0 3 3 3 1 2 1 1 3 0 0 0 1 0 3 0 0\n",
      " 2 3 2 0 2 2 3 2 1 3 2 2 3 2 0 0 2 2 0 0 2 2 0 0 3 3 2 2 2 2 2 1 2 0 3 2 3\n",
      " 0 2 1]\n",
      "Accuracy PCA + RANDOM CLASSIFIER: 0.5250836120401338\n"
     ]
    }
   ],
   "source": [
    "# PCA + RC\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(Pca_train_X,svm_y)\n",
    "pred_rc=clf.predict(Pca_test_X)\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_rc)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_rc)\n",
    "print('Accuracy PCA + RANDOM CLASSIFIER: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[1 2 1 2 2 3 1 0 2 3 0 2 0 2 2 3 1 2 1 2 2 1 1 0 2 2 2 0 2 1 3 2 2 2 2 3 2\n",
      " 0 1 1 2 1 1 2 2 0 3 1 3 2 2 3 0 1 0 1 3 3 3 2 1 2 1 1 1 2 1 3 2 0 1 0 3 2\n",
      " 1 2 0 0 1 1 2 2 0 0 0 0 0 1 1 1 2 2 1 0 0 2 2 0 2 0 2 3 3 1 1 1 0 0 0 3 1\n",
      " 1 1 1 2 3 3 1 3 2 2 3 2 2 2 0 3 0 3 2 2 1 2 2 2 3 3 2 3 1 1 0 3 1 2 0 3 0\n",
      " 2 1 2 1 2 0 2 3 3 1 3 3 2 1 0 3 0 1 2 2 2 0 3 0 3 1 0 1 3 1 3 2 2 1 0 1 3\n",
      " 2 2 3 1 0 3 3 2 2 1 2 3 1 0 2 2 3 0 1 0 3 1 3 2 1 1 2 1 2 3 2 1 2 2 2 1 3\n",
      " 0 1 2 3 3 3 3 3 3 3 0 2 1 1 1 2 1 3 1 3 1 2 1 3 1 0 1 1 3 0 3 3 1 3 0 0 2\n",
      " 2 2 0 1 2 2 3 0 1 3 0 0 0 0 0 1 3 2 2 0 2 1 3 1 3 3 2 3 0 2 2 1 2 0 3 3 3\n",
      " 0 2 1]\n",
      "Accuracy PCA + KNN : 0.6287625418060201\n"
     ]
    }
   ],
   "source": [
    "# PCA + KNN IMPLEMENTATION\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(Pca_train_X, svm_y)\n",
    "pred_knn=neigh.predict(Pca_test_X)\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_knn)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_knn)\n",
    "print('Accuracy PCA + KNN : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[1 0 1 3 2 2 1 0 2 3 0 2 0 3 0 3 1 1 1 2 2 1 1 3 2 2 2 3 2 0 3 2 2 2 2 2 2\n",
      " 0 1 1 2 3 0 2 3 0 3 1 2 2 3 2 2 1 0 1 3 2 3 3 1 0 1 1 1 2 1 2 3 2 2 0 3 0\n",
      " 1 2 0 3 2 1 3 2 0 0 0 0 0 1 1 1 2 3 0 0 0 2 2 0 2 0 2 2 3 1 2 1 2 2 2 0 1\n",
      " 0 1 1 0 3 0 1 0 2 2 3 2 0 3 2 3 3 0 3 2 1 2 2 3 0 0 3 0 1 0 0 0 1 1 2 0 0\n",
      " 2 2 2 1 2 3 2 2 2 1 0 0 2 1 3 0 0 1 2 2 0 0 3 0 3 1 3 1 2 2 0 2 0 1 0 1 3\n",
      " 2 2 3 1 0 0 2 2 2 1 0 2 1 0 3 3 3 0 1 3 1 1 0 2 1 0 1 2 3 1 2 1 2 2 2 1 2\n",
      " 0 1 3 3 2 3 2 3 0 0 2 3 1 1 1 3 0 0 3 0 1 2 3 3 1 2 1 1 0 1 2 0 1 3 3 0 3\n",
      " 2 2 2 1 2 0 0 0 1 3 2 0 0 2 3 3 2 2 0 0 2 1 0 2 3 0 2 0 0 2 2 1 2 0 2 2 3\n",
      " 3 2 1]\n",
      "Accuracy PCA + LinearDiscriminantAnalysis : 0.5886287625418061\n"
     ]
    }
   ],
   "source": [
    "# PCA + LinearDiscriminantAnalysis IMPLEMENTATION\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(Pca_train_X, svm_y)\n",
    "pred_LinearDiscriminantAnalysis=clf.predict(Pca_test_X)\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_LinearDiscriminantAnalysis)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_LinearDiscriminantAnalysis)\n",
    "print('Accuracy PCA + LinearDiscriminantAnalysis : {}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[0 1 1 3 1 2 1 0 3 2 1 1 0 3 0 3 1 0 1 3 1 1 1 2 2 1 1 2 1 2 3 2 1 1 2 1 1\n",
      " 0 1 1 0 0 0 2 2 2 2 1 1 2 3 2 1 1 1 1 1 1 1 2 3 1 1 1 1 3 1 0 2 1 2 0 2 0\n",
      " 1 2 3 1 1 1 3 2 2 2 1 1 2 1 1 1 1 3 1 2 0 2 2 2 0 0 1 3 1 0 1 1 3 1 2 1 1\n",
      " 3 1 1 0 2 0 1 1 2 0 2 1 2 1 2 2 1 2 1 1 1 2 2 2 0 3 2 1 1 1 0 1 1 0 1 2 2\n",
      " 2 1 2 0 2 2 2 2 1 1 1 1 1 1 3 2 1 1 2 2 0 0 3 2 0 1 3 3 2 1 1 2 0 1 2 1 2\n",
      " 2 2 1 1 0 1 0 2 2 1 2 2 1 2 3 0 1 0 1 1 0 1 1 2 1 1 0 2 3 3 1 1 2 1 1 1 1\n",
      " 0 0 2 3 2 2 2 1 2 1 2 1 1 1 1 3 1 0 0 2 1 3 3 3 1 1 1 1 0 3 0 1 1 0 2 0 2\n",
      " 1 2 1 0 1 1 0 2 1 2 2 0 0 2 3 0 0 2 0 1 1 2 2 1 3 0 2 2 2 2 2 1 2 0 2 2 2\n",
      " 3 2 1]\n",
      "Accuracy PCA + GaussianNB : 0.4080267558528428\n"
     ]
    }
   ],
   "source": [
    "# PCA + GaussianNB IMPLEMENTATION\n",
    "clf = GaussianNB()\n",
    "clf.fit(Pca_train_X, svm_y)\n",
    "pred_GaussianNB=clf.predict(Pca_test_X)\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_GaussianNB)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_GaussianNB)\n",
    "print('Accuracy PCA + GaussianNB : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 1, 1, 2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 3, 0, 3, 1, 1, 0, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 2, 0, 2, 0, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 0, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 3, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 2, 3, 3, 3, 3, 3, 2, 3, 0, 2, 1, 1, 1, 0, 2, 0, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 3, 3, 2, 1]\n",
      "[0 1 1 0 2 3 1 0 3 0 2 3 0 3 1 2 1 1 1 3 1 1 1 3 3 2 0 0 3 3 3 2 2 2 2 2 2\n",
      " 0 1 1 3 0 3 3 3 0 3 1 2 2 0 2 2 2 2 1 0 3 3 3 0 3 0 1 1 3 1 2 2 2 2 2 0 2\n",
      " 3 2 0 2 2 0 0 2 3 3 0 2 0 1 1 1 2 3 2 1 3 2 2 2 2 2 3 1 3 3 1 2 1 2 2 0 1\n",
      " 1 1 1 2 0 0 1 3 2 1 3 3 0 3 0 3 0 0 2 2 1 3 2 0 1 3 0 2 1 1 0 0 3 0 2 1 1\n",
      " 3 3 3 3 0 2 2 2 3 0 0 0 2 1 0 0 1 1 2 2 2 1 2 3 2 1 2 1 2 2 0 2 0 1 0 1 3\n",
      " 2 2 3 1 1 0 2 3 2 1 2 3 0 2 0 3 0 0 1 2 1 0 0 3 2 0 0 0 2 3 2 1 0 2 2 1 0\n",
      " 3 1 1 3 1 3 3 3 2 3 0 2 1 1 2 0 3 0 1 3 1 1 0 3 1 2 1 1 2 0 3 2 1 0 3 2 2\n",
      " 2 3 0 0 2 2 3 0 1 3 2 0 3 0 0 3 1 2 2 0 2 1 3 1 3 3 2 3 0 2 3 2 3 1 3 3 3\n",
      " 3 2 1]\n",
      "Accuracy pca + DecisionTreeClassifier : 0.4882943143812709\n"
     ]
    }
   ],
   "source": [
    "# PCA + DecisionTreeClassifier \n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(Pca_train_X, svm_y)\n",
    "pred_DecisionTreeClassifier=clf.predict(Pca_test_X)\n",
    "score=metrics.accuracy_score(Label_OF_test_data, pred_DecisionTreeClassifier)\n",
    "print(Label_OF_test_data)\n",
    "print(pred_DecisionTreeClassifier)\n",
    "print('Accuracy pca + DecisionTreeClassifier : {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is for LBP and Ml algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "# \n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1228/1228 [00:13<00:00, 94.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# loading the training data\n",
    "hist_train=[]\n",
    "label_b4 = []\n",
    "hist_train_label=[]\n",
    "for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "\n",
    "    # labeling the images\n",
    "    label = label_img(img)\n",
    "    label_b4.append(label)\n",
    "    path = os.path.join(TRAIN_DIR, img)\n",
    "\n",
    "    # loading the image from the path and then converting them into\n",
    "    # greyscale for easier covnet prob\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # resizing the image for processing them in the covnet\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    lbp = feature.local_binary_pattern(img, 24,8, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(),\n",
    "        bins=np.arange(0, 24+ 3),\n",
    "        range=(0, 24+2))\n",
    "\n",
    "    # normalize the histogram\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    hist_train.append(hist)\n",
    "        # final step-forming the training data list with numpy array of the images\n",
    "#         training_data.append([np.array(img), np.array(label)])\n",
    " \n",
    "#     # shuffling of the training data to preserve the random state of our data\n",
    "#     shuffle(training_data)\n",
    " \n",
    "#     # saving our trained data for further uses if required\n",
    "#     np.save('train_data.npy', training_data)\n",
    "hist_train[0:5]\n",
    "for val in label_b4:\n",
    "    if np.argmax(val) == 0:\n",
    "#         str_label ='Happy'\n",
    "        hist_train_label.append(0)\n",
    "    elif np.argmax(val) == 1:\n",
    "#         str_label ='sad'\n",
    "        hist_train_label.append(1)\n",
    "    elif np.argmax(val) == 2:\n",
    "#         str_label ='Angry'\n",
    "        hist_train_label.append(2)\n",
    "    elif np.argmax(val) == 3:\n",
    "#         str_label ='normal'\n",
    "        hist_train_label.append(3)\n",
    "\n",
    "# svm_y[0:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_train_label[1227]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=100.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(C=100.0, random_state=42)\n",
    "model.fit(hist_train, hist_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 299/299 [00:03<00:00, 85.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0588, 0.0548, 0.0404, 0.0204, 0.0172, 0.0248, 0.0164, 0.0116,\n",
      "       0.0212, 0.01  , 0.0132, 0.018 , 0.0104, 0.0224, 0.0104, 0.018 ,\n",
      "       0.0052, 0.0112, 0.0032, 0.006 , 0.0024, 0.0084, 0.008 , 0.0172,\n",
      "       0.0208, 0.5496]), array([0.0792, 0.042 , 0.0336, 0.0156, 0.0096, 0.0096, 0.0132, 0.0112,\n",
      "       0.01  , 0.0088, 0.004 , 0.0068, 0.004 , 0.0084, 0.004 , 0.0144,\n",
      "       0.0068, 0.0172, 0.0084, 0.0136, 0.0064, 0.0072, 0.01  , 0.0092,\n",
      "       0.0288, 0.618 ]), array([0.0776, 0.0488, 0.036 , 0.0156, 0.0092, 0.0092, 0.0136, 0.0132,\n",
      "       0.0076, 0.0068, 0.0036, 0.0044, 0.0036, 0.0064, 0.0032, 0.0148,\n",
      "       0.0048, 0.0168, 0.0104, 0.0124, 0.0064, 0.0116, 0.0088, 0.0128,\n",
      "       0.0256, 0.6168]), array([0.0696, 0.0408, 0.0312, 0.0176, 0.01  , 0.0108, 0.0196, 0.0152,\n",
      "       0.0148, 0.0128, 0.0092, 0.0056, 0.006 , 0.0096, 0.0068, 0.0148,\n",
      "       0.0076, 0.0184, 0.0096, 0.0096, 0.006 , 0.0064, 0.0072, 0.0104,\n",
      "       0.0292, 0.6012]), array([0.0696, 0.0596, 0.0336, 0.0172, 0.012 , 0.012 , 0.0104, 0.006 ,\n",
      "       0.004 , 0.0032, 0.0068, 0.0084, 0.0096, 0.008 , 0.006 , 0.0072,\n",
      "       0.0028, 0.0088, 0.006 , 0.0088, 0.0072, 0.0088, 0.0064, 0.0192,\n",
      "       0.0248, 0.6336])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading testing data \n",
    "hist_test=[]\n",
    "label_b4 = []\n",
    "hist_test_label=[]\n",
    "for img in tqdm(os.listdir(TEST_DIR)):\n",
    "\n",
    "    # labeling the images\n",
    "    label = label_img(img)\n",
    "    label_b4.append(label)\n",
    "    path = os.path.join(TEST_DIR, img)\n",
    "\n",
    "    # loading the image from the path and then converting them into\n",
    "    # greyscale for easier covnet prob\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # resizing the image for processing them in the covnet\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    lbp = feature.local_binary_pattern(img, 24,8, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(),\n",
    "        bins=np.arange(0, 24+ 3),\n",
    "        range=(0, 24+2))\n",
    "\n",
    "    # normalize the histogram\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    hist_test.append(hist)\n",
    "        # final step-forming the training data list with numpy array of the images\n",
    "#         training_data.append([np.array(img), np.array(label)])\n",
    " \n",
    "#     # shuffling of the training data to preserve the random state of our data\n",
    "#     shuffle(training_data)\n",
    " \n",
    "#     # saving our trained data for further uses if required\n",
    "#     np.save('train_data.npy', training_data)\n",
    "print(hist_test[0:5])\n",
    "for val in label_b4:\n",
    "    if np.argmax(val) == 0:\n",
    "#         str_label ='Happy'\n",
    "        hist_test_label.append(0)\n",
    "    elif np.argmax(val) == 1:\n",
    "#         str_label ='sad'\n",
    "        hist_test_label.append(1)\n",
    "    elif np.argmax(val) == 2:\n",
    "#         str_label ='Angry'\n",
    "        hist_test_label.append(2)\n",
    "    elif np.argmax(val) == 3:\n",
    "#         str_label ='Angry'\n",
    "        hist_test_label.append(3)\n",
    "hist_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 2 2 2 2 2 0 1 0 2 2 2 0 2 0 3 2 2 2 3 3 3 3 3 3 3 2 2 2 2 2 1 1 1 2 2 1\n",
      " 2 2 2 2 2 2 2 3 2 2 0 0 0 0 0 0 0 2 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 0 0\n",
      " 0 2 0 0 0 0 3 0 0 0 0 0 0 0 0 2 2 2 2 0 3 2 3 0 1 3 2 3 3 1 1 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 3 1 3 1 3 0 2 1 2 3 3 3 3 0 3 1 0 1 2 2 0 3 2 3 3 0 2 3\n",
      " 0 0 3 0 0 0 2 1 0 0 0 0 2 2 3 3 2 3 2 0 3 0 0 0 0 0 0 0 0 3 2 0 0 2 3 2 2\n",
      " 2 2 2 2 2 2 0 3 3 2 0 0 2 3 2 3 3 2 0 0 0 3 0 2 3 0 2 2 2 2 0 2 0 0 0 0 2\n",
      " 2 0 0 0 0 1 0 0 1 1 1 0 2 2 0 1 2 2 2 1 1 1 1 2 1 1 1 1 0 1 1 1 2 1 0 2 2\n",
      " 1 1 1 3 1 1 2 2 1 1 1 1 1 2 1 1 1 2 1 0 1 1 3 1 3 1 1 0 1 1 1 2 2 2 2 1 2\n",
      " 1 1 1]\n",
      "Accuracy LinearSVC: 0.40468227424749165\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(hist_test)\n",
    "\n",
    "score=metrics.accuracy_score(hist_test_label, prediction)\n",
    "print(hist_test_label)\n",
    "print(prediction)\n",
    "print('Accuracy LinearSVC: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[3 2 2 2 2 2 0 0 0 0 2 2 0 3 0 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 1 0 2 3 1\n",
      " 2 2 2 2 2 3 2 2 2 2 3 3 1 0 0 2 0 2 0 2 2 2 2 2 2 2 2 2 3 0 2 2 2 2 2 0 3\n",
      " 0 0 0 0 2 0 3 3 2 0 0 0 0 3 0 2 2 2 2 0 3 3 0 3 0 1 2 0 3 1 1 2 0 2 2 2 0\n",
      " 3 2 2 2 2 2 0 2 1 2 0 0 0 0 0 0 0 3 0 3 3 3 0 0 2 3 2 2 0 0 0 2 3 0 3 2 1\n",
      " 0 0 3 2 0 0 2 0 0 0 0 0 3 2 2 2 2 0 2 0 0 0 2 0 0 0 3 0 2 2 3 0 0 2 3 2 2\n",
      " 3 2 2 2 3 2 0 3 3 2 0 0 3 3 3 3 3 2 0 0 3 3 3 3 3 3 2 2 0 2 0 0 0 0 0 0 2\n",
      " 3 0 0 0 3 3 0 1 1 1 1 0 2 2 1 0 2 1 3 1 1 1 0 3 1 1 1 1 0 0 1 1 0 2 2 2 2\n",
      " 1 1 1 1 1 2 1 2 1 1 1 1 1 1 0 1 1 2 2 0 1 1 0 1 1 1 1 1 1 1 1 3 2 0 2 1 1\n",
      " 1 3 1]\n",
      "Accuracy LBP + RANDOM CLASSIFIER: 0.4816053511705686\n"
     ]
    }
   ],
   "source": [
    "# LBP + RC\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(hist_train,hist_train_label)\n",
    "pred_rc=clf.predict(hist_test)\n",
    "score=metrics.accuracy_score(hist_test_label, pred_rc)\n",
    "print(hist_test_label)\n",
    "print(pred_rc)\n",
    "print('Accuracy LBP + RANDOM CLASSIFIER: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 0 0 3 2 0 0 0 0 3 0 2 1 2 0 0 1 2 3 2 2 2 2 2 2 2 2 2 2 2 0 1 2 0 2 2 2\n",
      " 2 2 0 2 2 2 2 2 2 2 0 3 0 0 0 0 0 2 0 0 2 2 1 1 2 2 2 2 0 3 2 2 2 2 2 0 3\n",
      " 2 2 0 0 1 0 0 0 2 0 0 0 0 3 0 2 2 3 2 0 1 0 2 0 1 3 2 0 2 1 1 0 0 2 2 0 0\n",
      " 0 0 3 0 0 2 0 0 1 2 0 1 0 0 0 2 0 1 2 0 3 3 0 0 3 0 2 3 0 3 0 0 0 3 0 2 0\n",
      " 2 3 2 0 3 3 3 0 1 2 0 2 2 3 2 1 0 3 2 3 1 0 2 0 1 3 3 2 0 2 1 3 0 0 3 3 2\n",
      " 3 2 2 2 3 1 1 3 3 2 0 0 3 3 3 2 3 2 0 3 0 2 2 3 3 2 2 0 0 2 0 0 3 0 2 1 2\n",
      " 0 0 0 1 0 1 3 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 3 0 0 1 0 0 2 0 2\n",
      " 0 1 1 1 0 3 1 0 1 1 1 0 1 1 0 1 3 1 1 0 0 1 1 3 2 1 1 3 1 1 1 2 3 1 0 1 3\n",
      " 1 1 1]\n",
      "Accuracy LBP + KNN : 0.4916387959866221\n"
     ]
    }
   ],
   "source": [
    "# LBP + KNN IMPLEMENTATION\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(hist_train, hist_train_label)\n",
    "pred_knn=neigh.predict(hist_test)\n",
    "score=metrics.accuracy_score(hist_test_label, pred_knn)\n",
    "print(hist_test_label)\n",
    "print(pred_knn)\n",
    "print('Accuracy LBP + KNN : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 2 2 2 2 2 0 1 0 2 2 2 0 2 0 3 3 2 2 3 3 3 3 3 3 3 2 2 2 2 2 1 1 1 2 2 1\n",
      " 2 2 2 2 1 2 3 3 2 1 0 0 0 0 1 0 0 2 0 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 0 0\n",
      " 2 2 0 0 0 0 3 3 0 0 0 0 0 0 3 2 2 2 2 0 3 2 3 0 1 3 2 0 3 1 1 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 0 1 0 1 0 0 0 1 1 3 3 3 3 0 3 0 0 1 2 2 0 3 2 3 3 0 2 3\n",
      " 0 0 0 0 0 0 2 1 0 0 0 0 2 2 3 3 2 0 2 0 3 0 0 0 0 0 0 0 1 3 3 0 0 2 3 2 2\n",
      " 2 2 2 2 2 2 0 2 3 2 0 0 0 3 2 3 3 3 0 0 0 0 0 2 3 0 2 2 3 2 0 3 0 0 0 0 2\n",
      " 2 0 0 0 0 1 0 0 1 1 1 0 2 2 0 1 2 2 2 1 1 1 1 1 1 1 1 1 0 1 1 1 0 2 0 2 2\n",
      " 1 1 1 1 1 1 3 2 1 1 1 1 1 2 1 1 1 2 1 0 1 1 3 1 3 0 1 0 1 1 1 3 2 2 0 1 2\n",
      " 1 0 1]\n",
      "Accuracy LBP + LinearDiscriminantAnalysis : 0.40468227424749165\n"
     ]
    }
   ],
   "source": [
    "# LBP + LinearDiscriminantAnalysis IMPLEMENTATION\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(hist_train, hist_train_label)\n",
    "pred_LinearDiscriminantAnalysis=clf.predict(hist_test)\n",
    "score=metrics.accuracy_score(hist_test_label, pred_LinearDiscriminantAnalysis)\n",
    "print(hist_test_label)\n",
    "print(pred_LinearDiscriminantAnalysis)\n",
    "print('Accuracy LBP + LinearDiscriminantAnalysis : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 2 2 2 2 2 2 1 1 2 2 1 3 2 0 1 2 1 3 3 3 2 2 2 2 3 2 2 2 2 2 1 1 3 2 3 2\n",
      " 2 2 2 2 1 2 3 3 3 1 0 3 1 0 1 0 0 2 0 2 3 2 1 2 2 2 2 1 3 0 2 1 1 2 2 0 3\n",
      " 0 2 2 0 1 3 3 3 3 0 0 0 0 0 2 1 1 2 1 2 3 3 3 3 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
      " 2 2 1 2 2 2 2 2 1 3 0 0 0 0 0 1 1 2 3 3 2 3 3 3 3 3 2 3 3 1 0 3 3 0 3 2 1\n",
      " 0 3 3 3 3 3 2 3 2 3 3 0 2 2 3 2 2 3 3 3 1 2 0 0 0 0 3 3 2 3 0 0 0 2 3 1 2\n",
      " 3 2 2 2 2 2 0 2 2 2 0 0 2 3 2 2 3 2 0 0 0 0 0 0 3 0 3 2 2 2 0 1 0 0 0 2 2\n",
      " 2 0 1 3 3 1 1 1 1 1 1 0 1 1 1 1 1 1 2 2 1 1 1 3 1 1 1 1 0 1 1 1 2 2 0 2 1\n",
      " 1 1 1 1 1 1 3 2 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 3 1 1 3 1 1\n",
      " 1 2 1]\n",
      "Accuracy LBP + GaussianNB : 0.4280936454849498\n"
     ]
    }
   ],
   "source": [
    "# LBP + GaussianNB IMPLEMENTATION\n",
    "clf = GaussianNB()\n",
    "clf.fit(hist_train, hist_train_label)\n",
    "pred_GaussianNB=clf.predict(hist_test)\n",
    "score=metrics.accuracy_score(hist_test_label, pred_GaussianNB)\n",
    "print(hist_test_label)\n",
    "print(pred_GaussianNB)\n",
    "print('Accuracy LBP + GaussianNB : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[2 3 2 3 2 0 0 1 0 2 3 2 0 2 0 3 3 3 2 3 2 3 3 2 2 2 2 2 3 2 2 1 1 0 1 3 1\n",
      " 3 1 3 2 2 0 2 2 2 2 3 3 2 0 0 3 3 0 1 2 2 2 1 2 2 2 2 3 3 3 3 3 2 3 2 2 3\n",
      " 0 0 2 0 0 2 2 0 2 0 2 0 0 0 0 1 3 3 3 0 1 3 3 1 1 2 2 2 3 2 1 0 0 2 2 2 2\n",
      " 2 3 2 1 0 2 0 2 2 0 0 2 0 3 2 3 3 3 2 2 2 0 3 3 3 3 0 3 2 1 0 3 3 3 0 2 2\n",
      " 3 3 3 3 2 2 2 3 0 0 2 3 2 0 2 2 2 1 1 1 1 3 3 1 1 0 0 1 0 0 2 0 2 2 3 2 2\n",
      " 3 1 2 2 0 2 3 0 3 0 1 0 0 3 3 2 2 0 0 3 1 2 0 1 3 3 2 0 3 2 3 3 3 2 2 3 1\n",
      " 0 0 3 0 0 2 2 1 1 1 0 0 2 0 3 3 3 2 3 1 1 1 1 3 1 1 3 1 3 3 1 1 0 3 3 2 2\n",
      " 1 3 1 2 1 2 0 3 1 1 1 1 2 0 1 3 3 2 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 3 1 3\n",
      " 3 3 1]\n",
      "Accuracy LBP + DecisionTreeClassifier : 0.35451505016722407\n"
     ]
    }
   ],
   "source": [
    "# LBP + DecisionTreeClassifier \n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(hist_train, hist_train_label)\n",
    "pred_DecisionTreeClassifier=clf.predict(hist_test)\n",
    "score=metrics.accuracy_score(hist_test_label, pred_DecisionTreeClassifier)\n",
    "print(hist_test_label)\n",
    "print(pred_DecisionTreeClassifier)\n",
    "print('Accuracy LBP + DecisionTreeClassifier : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
